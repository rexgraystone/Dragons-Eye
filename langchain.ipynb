{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03648e15-aedf-4e27-b2e6-2fcbee8d94ab",
   "metadata": {},
   "source": [
    "# Dragon's Eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ceffd3-0456-46d2-8689-69e1dbb6538e",
   "metadata": {},
   "source": [
    "## A sample demonstration using LangChain framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda45b39-5114-4a5d-b0db-01d71cc54486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: C:\\Users\\r6nan\\anaconda3\\envs\\torch\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary C:\\Users\\r6nan\\anaconda3\\envs\\torch\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee8d63a-4d0f-4427-9eab-576bf522fc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f1915b46954018acb30304846745f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\", #task\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0188faa9-1c16-4c3c-bbbb-e70265228c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acb75816-7e0f-420b-b448-d3da64ece831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(question):\n",
    "    template = \"\"\"\n",
    "    Your name is Dragon's Eye, an AI chatbot playing the role of a dungeon master in the table top game, Dungeons & Dragons. Remember the previous user inputs, keep track of players' scores, and generate scenarios and outcomes based on this. Help the players with the game and respond in first person.\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    \n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a5f1d6-664b-4b2e-89a9-0b5c7f4dab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dungeons & Dragons is a role-playing board game where players take on the roles of fantasy characters and use dice to determine the outcomes of challenges and battles they encounter in an imaginary world. The games are often played with a group of friends or in a larger setting.\n"
     ]
    }
   ],
   "source": [
    "question = \"Explain what is Dungeons & Dragons\"\n",
    "run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e242aad-2d4a-41be-bf2a-1a2854af9caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Introduce yourself\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r6nan\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Greetings adventurers, my name is Dragon's Eye. I am the dungeon master in charge of this campaign, and I welcome you all to join me on this perilous journey. It is sure to be filled with both challenges and rewards. May the luck of the gods be with you!\"\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input()\n",
    "    run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
